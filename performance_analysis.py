import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from realistic_prediction import RealisticLMPPredictor
import warnings
warnings.filterwarnings('ignore')

class PerformanceAnalyzer:
    """è¯¦ç»†çš„é¢„æµ‹æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self.predictor = RealisticLMPPredictor()
    
    def detailed_performance_analysis(self, data_path: str = "applicationData"):
        """è¿›è¡Œè¯¦ç»†çš„æ€§èƒ½åˆ†æ"""
        print("=" * 80)
        print("LMPå¼‚å¸¸æ£€æµ‹ - è¯¦ç»†æ€§èƒ½åˆ†æ")
        print("=" * 80)
        
        try:
            # 1. åŠ è½½æ•°æ®å¹¶è®­ç»ƒæ¨¡å‹
            loaded_data = self.predictor.load_all_data(data_path)
            if not loaded_data:
                raise ValueError("No data loaded")
            
            print("\n1. è®­ç»ƒæ¨¡å‹...")
            self.predictor.train_model_with_real_data(loaded_data)
            
            # 2. è·å–è®­ç»ƒæ•°æ®å’ŒçœŸå®æ ‡ç­¾
            X, y_true = self.predictor.prepare_training_data(loaded_data)
            
            # 3. åœ¨ä¸åŒé˜ˆå€¼ä¸‹è¿›è¡Œé¢„æµ‹
            thresholds = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]
            
            print(f"\n2. æ•°æ®æ¦‚å†µ:")
            print(f"   æ€»æ ·æœ¬æ•°: {len(X)}")
            print(f"   çœŸå®å¼‚å¸¸æ•°: {y_true.sum()}")
            print(f"   çœŸå®å¼‚å¸¸ç‡: {y_true.mean():.2%}")
            print(f"   æ—¶é—´è·¨åº¦: {len(X)} å°æ—¶")
            
            # 4. é˜ˆå€¼æ€§èƒ½åˆ†æ
            print(f"\n3. ä¸åŒé˜ˆå€¼ä¸‹çš„é¢„æµ‹æ€§èƒ½:")
            print("-" * 80)
            print(f"{'é˜ˆå€¼':<8} {'å‡†ç¡®ç‡':<8} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'F1åˆ†æ•°':<8} {'é¢„æµ‹å¼‚å¸¸æ•°':<10}")
            print("-" * 80)
            
            best_threshold = 0.3
            best_f1 = 0
            results_data = []
            
            for threshold in thresholds:
                predictions = self.predictor.predict_anomalies(X, threshold=threshold)
                y_pred = predictions['predictions']
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                accuracy = accuracy_score(y_true, y_pred)
                precision = precision_score(y_true, y_pred, zero_division=0)
                recall = recall_score(y_true, y_pred, zero_division=0)
                f1 = f1_score(y_true, y_pred, zero_division=0)
                
                print(f"{threshold:<8.2f} {accuracy:<8.3f} {precision:<8.3f} {recall:<8.3f} {f1:<8.3f} {y_pred.sum():<10}")
                
                # è®°å½•æœ€ä½³F1åˆ†æ•°çš„é˜ˆå€¼
                if f1 > best_f1:
                    best_f1 = f1
                    best_threshold = threshold
                
                results_data.append({
                    'threshold': threshold,
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1': f1,
                    'predicted_anomalies': y_pred.sum()
                })
            
            print(f"\nâœ… æœ€ä½³é˜ˆå€¼: {best_threshold} (F1åˆ†æ•°: {best_f1:.3f})")
            
            # 5. ä½¿ç”¨æœ€ä½³é˜ˆå€¼è¿›è¡Œè¯¦ç»†åˆ†æ
            print(f"\n4. ä½¿ç”¨æœ€ä½³é˜ˆå€¼ {best_threshold} çš„è¯¦ç»†åˆ†æ:")
            print("=" * 50)
            
            best_predictions = self.predictor.predict_anomalies(X, threshold=best_threshold)
            y_pred_best = best_predictions['predictions']
            y_prob_best = best_predictions['probabilities']
            
            # æ··æ·†çŸ©é˜µ
            cm = confusion_matrix(y_true, y_pred_best)
            tn, fp, fn, tp = cm.ravel()
            
            print(f"\næ··æ·†çŸ©é˜µ:")
            print(f"              é¢„æµ‹")
            print(f"        æ­£å¸¸    å¼‚å¸¸")
            print(f"å®é™… æ­£å¸¸  {tn:4d}    {fp:4d}")
            print(f"     å¼‚å¸¸  {fn:4d}    {tp:4d}")
            
            print(f"\næ€§èƒ½æŒ‡æ ‡è¯¦è§£:")
            print(f"â€¢ çœŸé˜³æ€§ (TP): {tp} - æ­£ç¡®æ£€æµ‹çš„å¼‚å¸¸")
            print(f"â€¢ å‡é˜³æ€§ (FP): {fp} - è¯¯æŠ¥çš„å¼‚å¸¸")
            print(f"â€¢ çœŸé˜´æ€§ (TN): {tn} - æ­£ç¡®è¯†åˆ«çš„æ­£å¸¸")
            print(f"â€¢ å‡é˜´æ€§ (FN): {fn} - æ¼æ£€çš„å¼‚å¸¸")
            print(f"â€¢ å‡†ç¡®ç‡: {(tp+tn)/(tp+tn+fp+fn):.3f} - æ€»ä½“æ­£ç¡®ç‡")
            print(f"â€¢ ç²¾ç¡®ç‡: {tp/(tp+fp) if (tp+fp) > 0 else 0:.3f} - é¢„æµ‹å¼‚å¸¸ä¸­çœŸæ­£å¼‚å¸¸çš„æ¯”ä¾‹")
            print(f"â€¢ å¬å›ç‡: {tp/(tp+fn) if (tp+fn) > 0 else 0:.3f} - çœŸå®å¼‚å¸¸ä¸­è¢«æ£€æµ‹å‡ºçš„æ¯”ä¾‹")
            print(f"â€¢ F1åˆ†æ•°: {2*tp/(2*tp+fp+fn) if (2*tp+fp+fn) > 0 else 0:.3f} - ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡")
            
            # 6. æ—¶é—´åºåˆ—åˆ†æ
            self.time_series_analysis(X, y_true, y_pred_best, y_prob_best)
            
            # 7. é”™è¯¯åˆ†æ
            self.error_analysis(X, y_true, y_pred_best, y_prob_best)
            
            # 8. å•†ä¸šä»·å€¼åˆ†æ
            self.business_value_analysis(tp, fp, fn, tn)
            
            return {
                'best_threshold': best_threshold,
                'best_f1': best_f1,
                'confusion_matrix': cm,
                'results_data': results_data
            }
            
        except Exception as e:
            print(f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def time_series_analysis(self, X, y_true, y_pred, y_prob):
        """æ—¶é—´åºåˆ—åˆ†æ"""
        print(f"\n5. æ—¶é—´åºåˆ—åˆ†æ:")
        print("=" * 30)
        
        # æŒ‰å°æ—¶ç»Ÿè®¡
        if 'hour' in X.columns:
            hour_stats = pd.DataFrame({
                'hour': X['hour'],
                'true_anomaly': y_true,
                'pred_anomaly': y_pred,
                'anomaly_prob': y_prob
            })
            
            hourly_summary = hour_stats.groupby('hour').agg({
                'true_anomaly': ['count', 'sum'],
                'pred_anomaly': 'sum',
                'anomaly_prob': 'mean'
            }).round(3)
            
            print("æŒ‰å°æ—¶ç»Ÿè®¡:")
            print("å°æ—¶  æ ·æœ¬æ•°  çœŸå®å¼‚å¸¸  é¢„æµ‹å¼‚å¸¸  å¹³å‡å¼‚å¸¸æ¦‚ç‡")
            print("-" * 45)
            for hour in sorted(hour_stats['hour'].unique()):
                hour_data = hour_stats[hour_stats['hour'] == hour]
                count = len(hour_data)
                true_anom = hour_data['true_anomaly'].sum()
                pred_anom = hour_data['pred_anomaly'].sum()
                avg_prob = hour_data['anomaly_prob'].mean()
                print(f"{int(hour):2d}    {count:4d}      {int(true_anom):4d}       {int(pred_anom):4d}      {avg_prob:.3f}")
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ¨¡å¼
        consecutive_errors = 0
        max_consecutive = 0
        for i in range(len(y_true)):
            if y_true.iloc[i] != y_pred[i]:
                consecutive_errors += 1
                max_consecutive = max(max_consecutive, consecutive_errors)
            else:
                consecutive_errors = 0
        
        print(f"\nè¿ç»­é¢„æµ‹é”™è¯¯æœ€å¤§é•¿åº¦: {max_consecutive} å°æ—¶")
    
    def error_analysis(self, X, y_true, y_pred, y_prob):
        """é”™è¯¯åˆ†æ"""
        print(f"\n6. é”™è¯¯åˆ†æ:")
        print("=" * 20)
        
        # å‡é˜³æ€§åˆ†æ
        false_positives = (y_true == 0) & (y_pred == 1)
        false_negatives = (y_true == 1) & (y_pred == 0)
        
        print(f"å‡é˜³æ€§ (è¯¯æŠ¥) æ¡ˆä¾‹æ•°: {false_positives.sum()}")
        print(f"å‡é˜´æ€§ (æ¼æ£€) æ¡ˆä¾‹æ•°: {false_negatives.sum()}")
        
        if false_positives.sum() > 0:
            fp_probs = y_prob[false_positives]
            print(f"å‡é˜³æ€§çš„å¼‚å¸¸æ¦‚ç‡èŒƒå›´: {fp_probs.min():.3f} - {fp_probs.max():.3f}")
            print(f"å‡é˜³æ€§çš„å¹³å‡å¼‚å¸¸æ¦‚ç‡: {fp_probs.mean():.3f}")
        
        if false_negatives.sum() > 0:
            fn_probs = y_prob[false_negatives]
            print(f"å‡é˜´æ€§çš„å¼‚å¸¸æ¦‚ç‡èŒƒå›´: {fn_probs.min():.3f} - {fn_probs.max():.3f}")
            print(f"å‡é˜´æ€§çš„å¹³å‡å¼‚å¸¸æ¦‚ç‡: {fn_probs.mean():.3f}")
        
        # æœ€æœ‰ä¿¡å¿ƒçš„é¢„æµ‹
        most_confident_anomaly = y_prob.argmax()
        least_confident_anomaly = y_prob[y_pred == 1].argmin() if (y_pred == 1).any() else None
        
        print(f"\næœ€æœ‰ä¿¡å¿ƒçš„å¼‚å¸¸é¢„æµ‹:")
        print(f"  ç´¢å¼•: {most_confident_anomaly}, æ¦‚ç‡: {y_prob[most_confident_anomaly]:.3f}, å®é™…: {'å¼‚å¸¸' if y_true.iloc[most_confident_anomaly] else 'æ­£å¸¸'}")
        
        if least_confident_anomaly is not None:
            print(f"æœ€ä¸ç¡®å®šçš„å¼‚å¸¸é¢„æµ‹:")
            indices = np.where(y_pred == 1)[0]
            if len(indices) > 0:
                idx = indices[least_confident_anomaly]
                print(f"  ç´¢å¼•: {idx}, æ¦‚ç‡: {y_prob[idx]:.3f}, å®é™…: {'å¼‚å¸¸' if y_true.iloc[idx] else 'æ­£å¸¸'}")
    
    def business_value_analysis(self, tp, fp, fn, tn):
        """å•†ä¸šä»·å€¼åˆ†æ"""
        print(f"\n7. å•†ä¸šä»·å€¼åˆ†æ:")
        print("=" * 25)
        
        # å‡è®¾æˆæœ¬ (å¯ä»¥æ ¹æ®å®é™…ä¸šåŠ¡è°ƒæ•´)
        cost_false_alarm = 1000      # å‡è­¦æŠ¥æˆæœ¬ (äººåŠ›è°ƒæŸ¥æˆæœ¬)
        cost_missed_anomaly = 10000  # æ¼æ£€æˆæœ¬ (æ½œåœ¨çš„å¸‚åœºæŸå¤±)
        benefit_caught_anomaly = 5000 # æˆåŠŸæ£€æµ‹çš„æ”¶ç›Š (é¿å…æŸå¤±)
        
        total_cost = fp * cost_false_alarm + fn * cost_missed_anomaly
        total_benefit = tp * benefit_caught_anomaly
        net_value = total_benefit - total_cost
        
        print(f"æˆæœ¬æ•ˆç›Šåˆ†æ (å‡è®¾å€¼):")
        print(f"â€¢ å‡è­¦æŠ¥æˆæœ¬: ${fp} Ã— ${cost_false_alarm:,} = ${fp * cost_false_alarm:,}")
        print(f"â€¢ æ¼æ£€æˆæœ¬: ${fn} Ã— ${cost_missed_anomaly:,} = ${fn * cost_missed_anomaly:,}")
        print(f"â€¢ æ£€æµ‹æ”¶ç›Š: ${tp} Ã— ${benefit_caught_anomaly:,} = ${tp * benefit_caught_anomaly:,}")
        print(f"â€¢ å‡€ä»·å€¼: ${net_value:,}")
        
        if net_value > 0:
            print(f"âœ… ç³»ç»Ÿäº§ç”Ÿæ­£ä»·å€¼")
        else:
            print(f"âŒ ç³»ç»Ÿäº§ç”Ÿè´Ÿä»·å€¼ - éœ€è¦ä¼˜åŒ–")
        
        # æ”¹è¿›å»ºè®®
        print(f"\næ”¹è¿›å»ºè®®:")
        if fp > tp:
            print(f"â€¢ å‡è­¦æŠ¥è¿‡å¤šï¼Œå»ºè®®æé«˜é¢„æµ‹é˜ˆå€¼")
        if fn > 0:
            print(f"â€¢ å­˜åœ¨æ¼æ£€ï¼Œå»ºè®®æ”¹è¿›ç‰¹å¾å·¥ç¨‹æˆ–æ¨¡å‹")
        if tp == 0:
            print(f"â€¢ æœªæ£€æµ‹åˆ°ä»»ä½•çœŸå®å¼‚å¸¸ï¼Œæ¨¡å‹éœ€è¦é‡æ–°è®­ç»ƒ")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = PerformanceAnalyzer()
    results = analyzer.detailed_performance_analysis()
    
    if results:
        print(f"\n" + "=" * 80)
        print("æ€»ç»“")
        print("=" * 80)
        print(f"âœ… åˆ†æå®Œæˆ")
        print(f"âœ… æœ€ä½³é˜ˆå€¼: {results['best_threshold']}")
        print(f"âœ… æœ€ä½³F1åˆ†æ•°: {results['best_f1']:.3f}")
        print(f"")
        print(f"ğŸ¯ å…³é”®å‘ç°:")
        print(f"  â€¢ å½“å‰æ¨¡å‹åœ¨æ£€æµ‹LMPå¼‚å¸¸æ–¹é¢æœ‰ä¸€å®šèƒ½åŠ›")
        print(f"  â€¢ éœ€è¦åœ¨ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¹‹é—´æ‰¾åˆ°å¹³è¡¡")
        print(f"  â€¢ å»ºè®®æ”¶é›†æ›´å¤šå†å²æ•°æ®ä»¥æ”¹å–„æ¨¡å‹æ€§èƒ½")

if __name__ == "__main__":
    main() 